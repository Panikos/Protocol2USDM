# Protocol2USDM

> ## ‚ö†Ô∏è Disclaimer: An Experiment in AI-Assisted Development
>
> **This project was built with one self-imposed rule:** *I would not write or edit a single line of code myself.*
>
> The goal was to answer a simple question:
>
> > *"Can someone with no coding experience build production-quality clinical software using only AI assistants?"*
>
> Every line of code in this repository was generated by AI coding assistants (Claude, GPT, Gemini). The human role was limited to:
> - Describing requirements and desired outcomes
> - Reviewing and approving AI-generated code
> - Providing feedback and requesting corrections
> - Testing functionality and reporting issues
>
> **As a result, this software:**
> - ‚ùå Is **not robust** ‚Äî edge cases may not be handled
> - ‚ùå Is **likely full of bugs** ‚Äî limited systematic testing
> - ‚ùå Has **not been thoroughly tested** ‚Äî no formal QA process
> - ‚ùå Is **NOT fit for any production environment**
> - ‚ùå Should **NOT be used for actual clinical trials or regulatory submissions**
>
> **This project exists solely as:**
> - ‚úÖ A **demonstrator** of AI-assisted development capabilities
> - ‚úÖ A **reference implementation** of USDM v4.0 extraction concepts
> - ‚úÖ An **experiment** in human-AI collaboration for software development
>
> *Use at your own risk. Contributions and improvements welcome.*

---

**Extract clinical protocol content into USDM v4.0 format**

Protocol2USDM is an automated pipeline that extracts, validates, and structures clinical trial protocol content into data conformant to the [CDISC USDM v4.0](https://www.cdisc.org/standards/foundational/usdm) model.

---

## üöÄ Try It Now

```bash
python main_v2.py .\input\Alexion_NCT04573309_Wilsons.pdf --full-protocol --enrich --sap .\input\Alexion_NCT04573309_Wilsons_SAP.pdf --model claude-opus-4-5 --view
```

Or with Gemini:
```bash
python main_v2.py .\input\Alexion_NCT04573309_Wilsons.pdf --full-protocol --enrich --sap .\input\Alexion_NCT04573309_Wilsons_SAP.pdf --model gemini-3-pro-preview --view
```

> **üí° Recommended Models:** `claude-opus-4-5` or `gemini-3-pro-preview` produce the best results. GPT-5.1 is currently not recommended due to inconsistent output quality.

This extracts the full protocol, enriches entities with NCI terminology codes, includes SAP analysis populations, and launches the interactive viewer.

---

## Features

- **Multi-Model Support**: Claude Opus 4.5, Gemini 3 Pro Preview (recommended), GPT-4o via unified provider interface
- **Vision-Validated Extraction**: Text extraction validated against actual PDF images
- **USDM v4.0 Compliant**: Outputs follow official CDISC schema with proper entity hierarchy
- **NCI Terminology Enrichment**: Automatic enrichment with official NCI codes via EVS API
- **Activity Group Hierarchy**: Groups represented as parent Activities with `childIds` (USDM v4.0 pattern)
- **SoA Footnotes**: Captured and stored as `CommentAnnotation` objects in `StudyDesign.notes`
- **Rich Provenance**: Every cell tagged with source (text/vision/both) for confidence tracking
- **CDISC CORE Validation**: Built-in conformance checking with local engine
- **Interactive Viewer**: Streamlit-based SoA review interface with collapsible sections

### Extraction Capabilities (v6.5)

| Module | Entities | CLI Flag |
|--------|----------|----------|
| **SoA** | Activity, PlannedTimepoint, Epoch, Encounter, CommentAnnotation | (default) |
| **Metadata** | StudyTitle, StudyIdentifier, Organization, Indication | `--metadata` |
| **Eligibility** | EligibilityCriterion, StudyDesignPopulation | `--eligibility` |
| **Objectives** | Objective, Endpoint, Estimand | `--objectives` |
| **Study Design** | StudyArm, StudyCell, StudyCohort | `--studydesign` |
| **Interventions** | StudyIntervention, AdministrableProduct, Substance | `--interventions` |
| **Narrative** | NarrativeContent, Abbreviation | `--narrative` |
| **Advanced** | StudyAmendment, GeographicScope, Country | `--advanced` |
| **Procedures** | Procedure, MedicalDevice, Ingredient, Strength | `--procedures` |
| **Scheduling** | Timing, Condition, TransitionRule, ScheduleTimelineExit | `--scheduling` |
| **Doc Structure** | NarrativeContentItem, StudyDefinitionDocument | `--docstructure` |
| **Amendments** | StudyAmendmentReason, ImpactedEntity | `--amendmentdetails` |

#### Conditional Sources (Additional Documents)

| Source | Entities | CLI Flag |
|--------|----------|----------|
| **SAP** | AnalysisPopulation, Characteristic | `--sap <path>` |
| **Site List** | StudySite, StudyRole, AssignedPerson | `--sites <path>` |

---

## Full Protocol Extraction

Extract everything with a single command:

```bash
python main_v2.py protocol.pdf --full-protocol
```

Or select specific sections:

```bash
python main_v2.py protocol.pdf --metadata --eligibility --objectives
python main_v2.py protocol.pdf --expansion-only --metadata  # Skip SoA
python main_v2.py protocol.pdf --procedures --scheduling   # New phases
```

With additional source documents:

```bash
python main_v2.py protocol.pdf --full-protocol --sap sap.pdf --sites sites.xlsx
```

Output: Individual JSONs + combined `protocol_usdm.json`

---

## Quick Start

```bash
# 1. Clone repository
git clone https://github.com/Panikos/Protocol2USDMv3.git
cd Protocol2USDMv3

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up API keys (.env file)
OPENAI_API_KEY=...
GOOGLE_API_KEY=...
CDISC_API_KEY=...
CLAUDE_API_KEY=...

# 4. Run the pipeline
```bash
python main_v2.py .\input\Alexion_NCT04573309_Wilsons.pdf --full-protocol --enrich --sap .\input\Alexion_NCT04573309_Wilsons_SAP.pdf --model claude-opus-4-5 --view
```

# 5. View results
streamlit run soa_streamlit_viewer.py
```

---

## Installation

### Requirements
- Python 3.9+
- API keys: OpenAI, Google AI, Claude AI, CDISC API

### Setup

```bash
# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Create .env file with API keys
echo "OPENAI_API_KEY=sk-your-key" > .env
echo "GOOGLE_API_KEY=AIza-your-key" >> .env
echo "CDISC_API_KEY=your-cdisc-key" >> .env
```

### CDISC CORE Engine (Optional)
For conformance validation, download the CORE engine:
```bash
python tools/core/download_core.py
```

**Note:** Get your CDISC API key from https://library.cdisc.org/ (requires CDISC membership)

---

## Usage

### Basic Usage

```bash
python main_v2.py <protocol.pdf> [options]
```

### Model Selection

```bash
# Use GPT-5.1 (not working well)
python main_v2.py protocol.pdf --model gpt-5.1

# Use Claude (preferred)
python main_v2.py protocol.pdf --model claude-opus-4-5

# Use Gemini 3 Pro Preview (preferred)
python main_v2.py protocol.pdf --model gemini-3-pro-preview

# Use Gemini 2.5 Pro
python main_v2.py protocol.pdf --model gemini-2.5-pro

# Use GPT-4o
python main_v2.py protocol.pdf --model gpt-4o
```

### Full Pipeline with Post-Processing

```bash
# Run SoA + enrichment + schema validation + CORE conformance
python main_v2.py protocol.pdf --soa

# Or run post-processing steps individually
python main_v2.py protocol.pdf --enrich              # Step 7: NCI terminology
python main_v2.py protocol.pdf --validate-schema     # Step 8: Schema validation
python main_v2.py protocol.pdf --conformance         # Step 9: CORE conformance
```

### Additional Options

```bash
--output-dir, -o           Output directory (default: output/<protocol_name>)
--pages, -p                Specific SoA page numbers (comma-separated)
--no-validate              Skip vision validation
--remove-hallucinations    Remove cells not confirmed by vision (default: keep all)
--confidence-threshold     Confidence threshold for hallucination removal (default: 0.7)
--view                     Launch Streamlit viewer after extraction
--no-view                  Don't launch viewer (default behavior)
--verbose, -v              Enable verbose output
--update-evs-cache         Update EVS terminology cache before enrichment
--update-cache             Update CDISC CORE rules cache (requires CDISC_API_KEY)
```

---

## Pipeline Steps

### SoA Extraction (Steps 1-4)

| Step | Description | Output File |
|------|-------------|-------------|
| 1 | Find SoA pages & analyze header structure (vision) | `4_header_structure.json` |
| 2 | Extract SoA data from text | `5_raw_text_soa.json` |
| 3 | Validate extraction against images | `6_validation_result.json` |
| 4 | Build SoA output | `9_final_soa.json` + `9_final_soa_provenance.json` |

### Expansion Phases (with `--full-protocol`)

| Phase | Entities | Output File | CLI Flag |
|-------|----------|-------------|----------|
| Metadata | StudyTitle, Organization, Indication | `2_study_metadata.json` | `--metadata` |
| Eligibility | EligibilityCriterion, Population | `3_eligibility_criteria.json` | `--eligibility` |
| Objectives | Objective, Endpoint, Estimand | `4_objectives_endpoints.json` | `--objectives` |
| Study Design | StudyArm, StudyCell, StudyCohort | `5_study_design.json` | `--studydesign` |
| Interventions | StudyIntervention, Product, Substance | `6_interventions.json` | `--interventions` |
| Narrative | Abbreviation, NarrativeContent | `7_narrative_structure.json` | `--narrative` |
| Advanced | StudyAmendment, GeographicScope, Country | `8_advanced_entities.json` | `--advanced` |
| Procedures | Procedure, MedicalDevice, Ingredient | `9_procedures_devices.json` | `--procedures` |
| Scheduling | Timing, Condition, TransitionRule | `10_scheduling_logic.json` | `--scheduling` |
| Doc Structure | NarrativeContentItem, StudyDefinitionDocument | `13_document_structure.json` | `--docstructure` |
| Amendments | StudyAmendmentReason, ImpactedEntity | `14_amendment_details.json` | `--amendmentdetails` |

### Conditional Sources (with `--sap` or `--sites`)

| Source | Entities | Output File |
|--------|----------|-------------|
| SAP Document | AnalysisPopulation, Characteristic | `11_sap_populations.json` |
| Site List | StudySite, StudyRole, AssignedPerson | `12_site_list.json` |

### Post-Processing

| Step | Description | Output File |
|------|-------------|-------------|
| Combine | Merge all extractions | `protocol_usdm.json` ‚≠ê |
| Terminology | NCI EVS code enrichment | `terminology_enrichment.json` |
| Schema Fix | Auto-fix schema issues (UUIDs, Codes) | `schema_validation.json` |
| USDM Validation | Validate against official USDM package | `usdm_validation.json` |
| Conformance | CDISC CORE rules validation | `conformance_report.json` |
| ID Mapping | Simple ID ‚Üí UUID mapping | `id_mapping.json` |
| Provenance | UUID-based provenance for viewer | `protocol_usdm_provenance.json` |

**Primary output:** `output/<protocol>/protocol_usdm.json`

---

## Output Structure

The output follows the USDM v4.0 schema with proper `Study ‚Üí StudyVersion ‚Üí StudyDesign` hierarchy.

For detailed output structure and entity relationships, see [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md#output-structure).

### Provenance Tracking

Provenance metadata is stored separately in `9_final_soa_provenance.json` and visualized in the Streamlit viewer:

| Source | Color | Meaning |
|--------|-------|---------|
| `both` | üü© Green | Confirmed (text + vision agree) |
| `text` | üü¶ Blue | Text-only (NOT confirmed by vision) |
| `vision` | üüß Orange | Vision-only (possible hallucination, needs review) |
| (none) | üî¥ Red | Orphaned (no provenance data) |

View provenance in the interactive viewer:
```bash
streamlit run soa_streamlit_viewer.py
```

**Note:** By default, all text-extracted cells are kept in the output. Use `--remove-hallucinations` to exclude cells not confirmed by vision.

### SoA Footnotes

Footnotes extracted from SoA tables are stored in `StudyDesign.notes` as USDM v4.0 `CommentAnnotation` objects:

```json
"notes": [
  {"id": "soa_fn_1", "text": "a. Within 32 days of administration", "instanceType": "CommentAnnotation"},
  {"id": "soa_fn_2", "text": "b. Participants admitted 10 hours prior", "instanceType": "CommentAnnotation"}
]
```

---

## Viewing Results

Launch the interactive Streamlit viewer:

```bash
streamlit run soa_streamlit_viewer.py
```

**Features:**
- Visual SoA table with color-coded provenance
- Epoch and encounter groupings
- Filtering by activity/timepoint
- Quality metrics dashboard
- Validation & conformance results tab
- Raw JSON inspection

---

## Model Benchmark

SoA extraction tested on Alexion Wilson's Disease protocol (Nov 2025):

| Model | Activities | Timepoints | Ticks | Vision Header | Recommendation |
|-------|------------|------------|-------|---------------|----------------|
| **Claude Opus 4.5** | 36 ‚úì | 24 ‚úì | 212 (100% confirmed) | ‚úÖ | **Best accuracy** |
| **Gemini 3 Pro Preview** | 36 ‚úì | 24 ‚úì | 210 | ‚úÖ | **Recommended** |
| **Gemini 2.5 Pro** | 36 ‚úì | 24 ‚úì | 207 (10 flagged) | ‚úÖ | Good, reliable |
| GPT-4o | 36 ‚úì | 24 ‚úì | 205 | ‚úÖ | Good alternative |

**Notes:**
- Claude Opus 4.5: Best overall - all ticks confirmed by vision validation
- Gemini 3 Pro Preview: Fast, accurate, recommended for most use cases
- Gemini 2.5 Pro: Good accuracy, flags potential hallucinations for review
- GPT-4o: Solid performance with vision support

---

## Project Structure

```
Protocol2USDMv3/
‚îú‚îÄ‚îÄ main_v2.py                # Main pipeline entry point
‚îú‚îÄ‚îÄ core/                     # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ usdm_schema_loader.py # Official CDISC schema parser + USDMEntity base
‚îÇ   ‚îú‚îÄ‚îÄ usdm_types_generated.py # 86+ auto-generated USDM types
‚îÇ   ‚îú‚îÄ‚îÄ usdm_types.py         # Unified type interface
‚îÇ   ‚îú‚îÄ‚îÄ evs_client.py         # NCI EVS API client with caching
‚îÇ   ‚îú‚îÄ‚îÄ provenance.py         # ProvenanceTracker for source tracking
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py         # LLM client
‚îÇ   ‚îî‚îÄ‚îÄ json_utils.py         # JSON utilities
‚îú‚îÄ‚îÄ extraction/               # Extraction modules
‚îÇ   ‚îú‚îÄ‚îÄ header_analyzer.py    # Vision-based structure
‚îÇ   ‚îú‚îÄ‚îÄ text_extractor.py     # Text-based extraction
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py           # SoA extraction pipeline
‚îÇ   ‚îú‚îÄ‚îÄ validator.py          # Extraction validation
‚îÇ   ‚îî‚îÄ‚îÄ */                    # Domain extractors (13 modules)
‚îú‚îÄ‚îÄ enrichment/               # Terminology enrichment
‚îÇ   ‚îî‚îÄ‚îÄ terminology.py        # NCI EVS enrichment
‚îú‚îÄ‚îÄ validation/               # Validation package
‚îÇ   ‚îú‚îÄ‚îÄ usdm_validator.py     # Official USDM validation
‚îÇ   ‚îî‚îÄ‚îÄ cdisc_conformance.py  # CDISC CORE conformance
‚îú‚îÄ‚îÄ prompts/                  # YAML prompt templates
‚îú‚îÄ‚îÄ testing/                  # Benchmarking & integration tests
‚îú‚îÄ‚îÄ utilities/                # Setup scripts
‚îú‚îÄ‚îÄ docs/                     # Architecture documentation
‚îú‚îÄ‚îÄ soa_streamlit_viewer.py   # Interactive viewer
‚îú‚îÄ‚îÄ tools/core/               # CDISC CORE engine
‚îî‚îÄ‚îÄ output/                   # Pipeline outputs
```

For detailed architecture, see [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md).

---

## Testing

```bash
# Run unit tests
pytest tests/

# Run integration tests
python testing/test_pipeline_steps.py

# Run golden standard comparison
python testing/compare_golden_vs_extracted.py

# Benchmark models
python testing/benchmark_models.py
```

---

## Configuration

### Environment Variables

```bash
# Required - at least one LLM provider
OPENAI_API_KEY=...          # For GPT models
GOOGLE_API_KEY=...          # For Gemini models
CLAUDE_API_KEY=...          # For Claude models (Anthropic)

# Required for CDISC conformance validation
CDISC_API_KEY=...           # For CORE rules cache (get from library.cdisc.org)
```

### Supported Models

**Anthropic (Recommended):**
- `claude-opus-4-5` ‚≠ê Best accuracy
- `claude-sonnet-4`

**Google (Recommended):**
- `gemini-3-pro-preview` ‚≠ê Fast & accurate
- `gemini-2.5-pro`
- `gemini-2.5-flash`
- `gemini-2.0-flash`

**OpenAI:**
- `gpt-4o`
- `gpt-4`

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| API key error | Check `.env` file, restart terminal |
| Missing visits | Verify correct SoA pages found (check `4_header_structure.json`) |
| Parse errors | Try different model, check verbose logs |
| Schema errors | Post-processing auto-fixes most issues |

---

## Roadmap / TODO

The following items are planned for upcoming releases:

- [ ] **Biomedical Concepts**: Add extraction via a separate comprehensive canonical model for standardized concept mapping
- [x] **StudyIdentifier Type Auto-Inference**: NCT, EudraCT, IND, Sponsor patterns auto-detected *(completed v6.5.0)*
- [x] **encounterId Alignment**: Extraction uses enc_N directly instead of pt_N *(completed v6.5.0)*
- [x] **EVS-Verified Terminology Codes**: All 28 NCI codes verified against NIH EVS API *(completed v6.5.0)*
- [x] **Provenance ID Consistency**: Idempotent UUID generation ensures provenance IDs match data *(completed v6.3.0)*
- [x] **NCI EVS Terminology Enrichment**: Real-time EVS API integration with local caching *(completed v6.3.0)*
- [x] **CDISC CORE Integration**: Local CORE engine for conformance validation with cache update *(completed v6.3.0)*
- [x] **Schema-Driven Architecture**: All types from official `dataStructure.yml` *(completed v6.2.0)*
- [x] **Repository Cleanup**: Cleaned codebase, archived orphaned files *(completed v6.3.0)*
- [x] **Activity Group Hierarchy**: Groups now use USDM v4.0 `childIds` pattern *(completed v6.1.2)*
- [x] **SoA Footnotes**: Stored as `CommentAnnotation` in `StudyDesign.notes` *(completed v6.1.2)*

---

## License

Contact author for permission to use.

---

## Acknowledgments

This project is, in many ways, a workflow wrapper around the incredible work done by [CDISC](https://www.cdisc.org/) and its volunteers. We stand on the shoulders of giants.

### CDISC & Data4Knowledge

A special thank you to the **Data4Knowledge (D4K) team** and the CDISC DDF community:

- **[DDF Reference Architecture](https://github.com/cdisc-org/DDF-RA)** - The USDM schema that powers this entire pipeline
- **[CDISC CORE Engine](https://github.com/cdisc-org/cdisc-rules-engine)** - Conformance validation rules
- **[usdm Python Package](https://pypi.org/project/usdm/)** - Official USDM validation library

Most importantly, heartfelt thanks to **Dave Iberson-Hurst**, **Kirsten Walther Langendorf**, and **Johannes Ulander** ‚Äî who have been extraordinarily kind and supportive despite my repeated questions and suggestions. Their openness in sharing their work enables projects like this to exist.

### Other Resources

- [NCI EVS](https://evs.nci.nih.gov/) for terminology services
